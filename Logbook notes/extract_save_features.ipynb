{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use extract_save_features from Labs\n",
    "- export train.pt and valid.pt to googledrive for easy access (no need to extract features again)\n",
    "- load extracted features using Tensordataset (torch.load())\n",
    "- look at feature .py files and see what we need to extract from them to create an ibject (???? correct term?)\n",
    "- create dataset from extracted features (why?)\n",
    "- currenty have LabsSolutions modules moved into cwd, but better bet might be to do it ina  forked git repo and run there saves time and code \n",
    "- have to look through testing again before running, reason why stopped is because there was no model created/input into !python test_single.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from /LabsSolutions/01-pytorch-object-detection/utils.py\n",
    "def extract_save_features(loader: torch.utils.data.DataLoader,\n",
    "                          model: torch.nn.Module,\n",
    "                          device: torch.device,\n",
    "                          filename_prefix: str):\n",
    "     \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        batch_idx = 1\n",
    "        for (inputs, targets) in tqdm(loader):\n",
    "\n",
    "            inputs = inputs.to(device=device)\n",
    "\n",
    "            # Compute the forward propagation through the body\n",
    "            # just to extract the features\n",
    "            features = model(inputs)\n",
    "\n",
    "            torch.save(dict([(\"features\", features)] + [(k, v.squeeze()) for (k,v) in targets.items()]),\n",
    "                       filename_prefix+\"{}.pt\".format(batch_idx))\n",
    "\n",
    "            batch_idx += 1\n",
    "\"\"\"The function extract_save_features saves a dictionary. Within the context of this section, the dictionnary that is saved will have :\n",
    "For the training set :\n",
    "the key ‘features’ with torch tensor of shape (5717, 512, 7, 7)\n",
    "the key ‘bboxes’ with torch tensor of shape (5717,4)\n",
    "the key ‘labels’ with torch tensor of shape (5717)\n",
    "For the validation set :\n",
    "the key ‘features’ with torch tensor of shape (5823, 512, 7, 7)\n",
    "the key ‘bboxes’ with torch tensor of shape (5823,4)\n",
    "the key ‘labels’ with torch tensor of shape (5823)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Labs/01-pytorch-object-detection/utils.py\n",
    "\n",
    "def extract_save_features(loader: torch.utils.data.DataLoader,\n",
    "                        model: torch.nn.Module,\n",
    "                        device: torch.device,\n",
    "                        filename: str):\n",
    "    \"\"\"The function extract_save_features saves a dictionary. Within the context of this section, the dictionnary that is saved will have :\n",
    "\n",
    "For the training set :\n",
    "the key ‘features’ with torch tensor of shape (5717, 512, 7, 7)\n",
    "the key ‘bboxes’ with torch tensor of shape (5717,4)\n",
    "the key ‘labels’ with torch tensor of shape (5717)\n",
    "For the validation set :\n",
    "the key ‘features’ with torch tensor of shape (5823, 512, 7, 7)\n",
    "the key ‘bboxes’ with torch tensor of shape (5823,4)\n",
    "the key ‘labels’ with torch tensor of shape (5823)\"\"\"\n",
    "    all_features = []\n",
    "    all_targets = defaultdict(list)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for (inputs, targets) in tqdm(loader):\n",
    "\n",
    "            inputs = inputs.to(device=device)\n",
    "\n",
    "            # Compute the forward propagation through the body\n",
    "            # just to extract the features\n",
    "            all_features.append(model(inputs))\n",
    "\n",
    "            for k, v in targets.items():\n",
    "                all_targets[k].append(v)\n",
    "\n",
    "        for k, v in all_targets.items():\n",
    "            all_targets[k] = torch.squeeze(torch.cat(v, 0))\n",
    "        all_features = torch.squeeze(torch.cat(all_features , 0))\n",
    "    print(all_features.shape)\n",
    "    print(\"The features that are saved are {} features maps of size {} x {}, with {} channels\".format(all_features.shape[0], all_features.shape[2], all_features.shape[3], all_features.shape[1]))\n",
    "    for k, v in all_targets.items():\n",
    "        print(\"The entry {} have shape {}\".format(k, v.shape))\n",
    "\n",
    "    torch.save(dict([(\"features\", all_features)] + list(all_targets.items())), filename)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "Key Differences:\n",
    "\n",
    "Filename Handling:\n",
    "\n",
    "Function 1: Accepts a single filename argument, implying it saves all extracted data (features, bounding boxes, labels) into a single file with that name.\n",
    "Function 2: Accepts a filename_prefix argument, suggesting it might save data into multiple files, using the prefix to differentiate them (e.g., filename_prefix_features.pt, filename_prefix_bboxes.pt, etc.).\n",
    "Data Saving Logic:\n",
    "\n",
    "Function 1: Saves all features, bounding boxes, and labels together in a dictionary and stores it as a single .pt file.\n",
    "Function 2: Could potentially save them as separate files or using a different dictionary structure, based on a user-defined parameter.\n",
    "Functionality:\n",
    "\n",
    "Function 1: Extracts features from a given model and combines them with target data (bboxes, labels). It then saves everything as a single file for use in another notebook.\n",
    "Function 2: Without the function body, it's unclear about its exact logic for saving features, bounding boxes, and labels. It could save them separately, combined in another form, or incorporate additional flexibility.\n",
    "In Summary:\n",
    "\n",
    "The main difference is how they handle the saving of data - using a single file vs. a prefix for multiple files. Additionally, function 2's behavior without its code is less specific, offering some room for differing data handling strategies. This likely affects its application and data usage within other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
